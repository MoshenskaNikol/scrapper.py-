# -*- coding: utf-8 -*-

import urllib2
from bs4 import BeautifulSoup
import re
import pandas as pd
import gc

# base = "https://zp.isuo.org"


url = "https://isuo.org/"

def scrapSchoolsByUrl(base, url):
    print("scraping url:", base + url)
    df = pd.DataFrame(columns=['index', 'name', 'email'])
    soupSchool = BeautifulSoup(urllib2.urlopen(base + url), 'html.parser')
    for school in soupSchool.findAll('a'):
        if "/schools/view/id" in school.get('href'):
            page = urllib2.urlopen(base + school.get("href"))
            soup = BeautifulSoup(page, 'html.parser')
            email = ""
            for link in soup.findAll('a'):
                if link.get('onclick'):
                    if "unescape" in link.get('onclick').encode("utf-8"):
                        raw = re.findall(r"\'(.+?)\'", link.get('onclick').encode("utf-8"))[0]
                        parsed = urllib2.unquote(raw)
                        email = re.findall(r">(.+?)<", parsed)[0]
                        print("parsing ", base + school.get("href"), "email ", email)
            df = df.append({'name': soup.title.string[0:-5], 'email': email}, ignore_index=True)
    with open("ukrainian_schools.csv", 'a') as f:
       df.to_csv(f, sep=',', encoding='utf-8')



soupCountry = BeautifulSoup(urllib2.urlopen(url), 'html.parser')
for country in soupCountry.findAll('a'):
    gc.collect()
    if ".isuo.org" in country.get('href') and "mon.isuo.org" not in country.get('href') and "irc.isuo.org" not in country.get('href') and "reg.isuo.org" not in country.get('href') and "at.isuo.org" not in country.get('href'):
            urlRegion = "https:" + country.get("href")
            # print("urlRegion", urlRegion)
            soupRegion = BeautifulSoup(urllib2.urlopen(urlRegion), 'html.parser')
            for region in soupRegion.findAll('a'):
                if "/authorities/view/id/" in region.get('href') and "mon.isuo.org" not in region.get('href') and ((region.text[-3:] ==u'\u041e\u0414\u0410') or (region.text[-5:-1] ==u'\u041a\u041c\u0414\u0410')):
                    urlSchools = urlRegion[:-1] + region.get("href")
                    print(region.text)
                    soupSchools = BeautifulSoup(urllib2.urlopen(urlSchools), 'html.parser')
                    for regionOdas in soupSchools.findAll('ul', {"class", "tabs"}):
                        for regionOda in regionOdas.findAll('a'):
                            if "/authorities/schools-list/id/" in regionOda.get('href'):
                                urlSchoolsInReg = urlRegion[:-1] + regionOda.get("href")[2:].strip();
                                # print(urlSchoolsInReg)
                                scrapSchoolsByUrl(urlRegion[:-1], regionOda.get("href")[2:].strip())
                                soupPage = BeautifulSoup(urllib2.urlopen(urlSchoolsInReg), 'html.parser')
                                page = 2
                                for scoolPage in soupPage.findAll("a"):
                                    urlPageForScrap = str(urlSchoolsInReg[urlRegion.__len__()-1:]) + "/page/" + str(page)
                                    if urlPageForScrap in scoolPage.get("href"):
                                        # print(urlPageForScrap)
                                        scrapSchoolsByUrl(str(urlRegion), urlPageForScrap)
                                        page = page + 1
